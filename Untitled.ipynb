{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from EPO import EPO_LP\n",
    "\n",
    "m = 3                                # int : task nums\n",
    "n = 100                              # int : parameter nums\n",
    "r = tf.ones([1,m])                   # tensor (1,m) : preference vector\n",
    "epo_lp = EPO_LP(m,n,r)\n",
    "losses = tf.reshape(tf.convert_to_tensor([0.15,0.42,2.30]),(1,m))   # tensor (1,m) : losses of different tasks\n",
    "GG =  tf.random_normal([m, m], stddev=0.5, seed=2)\n",
    "                                        # tensor (m,m) : GG = G @ G, product of gradient matrix\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        alpha = epo_lp.get_alpha(losses, G=GG, C=True)\n",
    "        print(sess.run(alpha))\n",
    "    except Exception as e:\n",
    "        print(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori\n",
      "[array([ 0.       , -3.5759819,  4.5759816], dtype=float32), array([[ 0.3       , -0.23000002, -0.18      ],\n",
      "       [-0.23000002,  0.33000004,  0.23000002],\n",
      "       [-0.18      ,  0.23000002,  0.38000003]], dtype=float32), array([[9.9979996e-05, 9.9980003e-01, 9.9979996e-05]], dtype=float32)]\n",
      "neg\n",
      "[array([ 0.       , -3.5759819,  4.5759816], dtype=float32), array([[ 0.3       , -0.23000002, -0.18      ],\n",
      "       [-0.23000002,  0.33000004,  0.23000002],\n",
      "       [-0.18      ,  0.23000002,  0.38000003]], dtype=float32), array([[9.9979996e-05, 9.9980003e-01, 9.9979996e-05]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from EPO import EPO_LP\n",
    "from EPO_allow_neg import EPO_LP as EPO_LP_neg\n",
    "\n",
    "m = 3                                # int : task nums\n",
    "n = 100                              # int : parameter nums\n",
    "r = tf.reshape(tf.constant([0.01,100,0.01]),[1,m])                   # tensor (1,m) : preference vector\n",
    "r /= tf.reduce_sum(r)\n",
    "epo_lp = EPO_LP(m,n,r)\n",
    "epo_lp_neg = EPO_LP_neg(m,n,r)\n",
    "losses = tf.reshape(tf.constant([0.15,0.42,2.30]),(1,m))   # tensor (1,m) : losses of different tasks\n",
    "# G = tf.constant([[0.3,0.2,0.1,0.6],[-0.3,-0.2,-0.1,-0.6],[0.1,0.0,-0.3,0.0]])\n",
    "G = tf.constant([[0.1,0.2,0.3,0.4],[-0.2,0.2,-0.3,-0.4],[0.3,0.2,-0.3,-0.4]])\n",
    "# G =  tf.random_normal([m, n], stddev=0.5,seed=2)\n",
    "GG = tf.matmul(G,G,transpose_b=True) \n",
    "\n",
    "# GG = tf.matmul(G,GG,transpose_b=True) \n",
    "                                        # tensor (m,m) : GG = G @ G, product of gradient matrix\n",
    "# value = tf.constant([1,2,3,4,5,6,7])\n",
    "# idx = tf.constant([7,9,20,2,3,1,5])\n",
    "\n",
    "# def del_idx(idx_src,idx_del):\n",
    "#     idx_src = tf.reshape(idx_src,[-1,1])\n",
    "#     idx_del = tf.reshape(idx_del,[1,-1])\n",
    "#     eq_mat = tf.to_float(tf.equal(idx_src,idx_del))\n",
    "#     idx_valid = tf.where(tf.equal(tf.reduce_sum(eq_mat,1),0))\n",
    "#     idx_src = tf.reshape(idx_src,[-1])\n",
    "#     idx_src = tf.gather(idx_src,idx_valid,axis=0)\n",
    "#     idx_src = tf.reshape(idx_src,[-1])\n",
    "#     return idx_src\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     c=del_idx(value,idx)\n",
    "#     print(sess.run(c))\n",
    "    alpha = epo_lp.get_alpha(losses, G=GG, C=True)\n",
    "    print 'ori'\n",
    "    print(sess.run([alpha,GG,r]))\n",
    "    alpha = epo_lp_neg.get_alpha(losses, G=GG, C=True)\n",
    "    print 'neg'\n",
    "    print(sess.run([alpha,GG,r]))\n",
    "#     GG = sess.run(GG)\n",
    "#     print GG\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori\n",
      "[array([0., 0., 1.], dtype=float32), array([[ 0.3       , -0.23000002, -0.18      ],\n",
      "       [-0.23000002,  0.33000004,  0.23000002],\n",
      "       [-0.18      ,  0.23000002,  0.38000003]], dtype=float32), array([[0.33333334, 0.33333334, 0.33333334]], dtype=float32)]\n",
      "neg\n",
      "[array([0.375, 0.   , 0.625], dtype=float32), array([[ 0.3       , -0.23000002, -0.18      ],\n",
      "       [-0.23000002,  0.33000004,  0.23000002],\n",
      "       [-0.18      ,  0.23000002,  0.38000003]], dtype=float32), array([[0.33333334, 0.33333334, 0.33333334]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from EPO import EPO_LP\n",
    "from EPO_allow_neg import EPO_LP as EPO_LP_neg\n",
    "\n",
    "m = 3                               # int : task nums\n",
    "n = 100                              # int : parameter nums\n",
    "r = tf.reshape(tf.constant([1.,1.,1.]),[1,m])                   # tensor (1,m) : preference vector\n",
    "r /= tf.reduce_sum(r)\n",
    "epo_lp = EPO_LP(m,n,r)\n",
    "epo_lp_neg = EPO_LP_neg(m,n,r)\n",
    "losses = tf.reshape(tf.constant([0.1,0.1,0.1]),(1,m))   # tensor (1,m) : losses of different tasks\n",
    "# G = tf.constant([[0.3,0.2,0.1,0.6],[-0.3,-0.2,-0.1,-0.6],[0.1,0.0,-0.3,0.0]])\n",
    "G = tf.constant([[0.1,0.2,0.3,0.4],[-0.2,0.2,-0.3,-0.4],[0.3,0.2,-0.3,-0.4]])\n",
    "# G =  tf.random_normal([m, n], stddev=0.5,seed=2)\n",
    "GG = tf.matmul(G,G,transpose_b=True) \n",
    "\n",
    "# GG = tf.matmul(G,GG,transpose_b=True) \n",
    "                                        # tensor (m,m) : GG = G @ G, product of gradient matrix\n",
    "# value = tf.constant([1,2,3,4,5,6,7])\n",
    "# idx = tf.constant([7,9,20,2,3,1,5])\n",
    "\n",
    "# def del_idx(idx_src,idx_del):\n",
    "#     idx_src = tf.reshape(idx_src,[-1,1])\n",
    "#     idx_del = tf.reshape(idx_del,[1,-1])\n",
    "#     eq_mat = tf.to_float(tf.equal(idx_src,idx_del))\n",
    "#     idx_valid = tf.where(tf.equal(tf.reduce_sum(eq_mat,1),0))\n",
    "#     idx_src = tf.reshape(idx_src,[-1])\n",
    "#     idx_src = tf.gather(idx_src,idx_valid,axis=0)\n",
    "#     idx_src = tf.reshape(idx_src,[-1])\n",
    "#     return idx_src\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     c=del_idx(value,idx)\n",
    "#     print(sess.run(c))\n",
    "    alpha = epo_lp.get_alpha(losses, G=GG, C=True)\n",
    "    print 'ori'\n",
    "    print(sess.run([alpha,GG,r]))\n",
    "    alpha = epo_lp_neg.get_alpha(losses, G=GG, C=True)\n",
    "    print 'neg'\n",
    "    print(sess.run([alpha,GG,r]))\n",
    "#     GG = sess.run(GG)\n",
    "#     print GG\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (EPO_CVX.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"EPO_CVX.py\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    obj_bal = cp.Maximize(self.alpha @ self.Ca)   # objective for balance\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from EPO_CVX import EPO_LP_CVX\n",
    "\n",
    "m = 3                                # int : task nums\n",
    "n = 100                              # int : parameter nums\n",
    "r = np.reshape(np.array([0.1,0.1,0.01]),[1,m])                   # tensor (1,m) : preference vector\n",
    "r /= np.sum(r)\n",
    "epo_lp_cvx = EPO_LP_CVX(m,n,r)\n",
    "losses = np.reshape(np.array([0.15,0.42,2.30]),(1,m))   # tensor (1,m) : losses of different tasks\n",
    "G = np.array([[0.3,0.2,0.1,0.6],[-0.3,-0.2,-0.1,-0.6],[0.1,0.0,-0.3,0.0]])\n",
    "GG = np.dot(G,G.T)\n",
    "\n",
    "alpha = epo_lp_cvx.get_alpha(losses, G=GG, C=True)\n",
    "print alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori\n",
      "[0. 1.]\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from EPO_VAL import EPO_LP \n",
    "from EPO_VAL_allow_neg import EPO_LP  as EPO_LP_neg\n",
    "\n",
    "m = 2                                # int : task nums\n",
    "n =  4                             # int : parameter nums\n",
    "r = tf.reshape(tf.constant([1.,1.]),[1,m])                   # tensor (1,m) : preference vector\n",
    "r /= tf.reduce_sum(r)\n",
    "epo_lp = EPO_LP(m,n)\n",
    "epo_lp_neg = EPO_LP_neg(m,n)\n",
    "losses = tf.reshape(tf.constant([0.1,0.1]),(1,m))   # tensor (1,m) : losses of different tasks\n",
    "G = tf.constant([[0.3,0.2,0.1,0.6],[-0.3,-0.2,-0.1,0.6] ])\n",
    "# GG =  tf.reshape(tf.constant([1.8524196e-02,5.8749327e-03,5.8749327e-03,6.1014127e-03],(m,m))\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "G_val = tf.reshape(tf.constant([-0.1,-0.2,-0.3,-0.4]),[1,n])    \n",
    "loss_val = 0.1\n",
    "\n",
    "rl = tf.reshape(tf.reduce_mean(G * G_val, axis=1),[1, m])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print 'ori'\n",
    "    alpha = epo_lp.get_alpha(losses, G,G_val,loss_val, C=True)\n",
    "    print(sess.run(alpha))\n",
    "    print 'neg'\n",
    "    alpha = epo_lp_neg.get_alpha(losses, G,G_val,loss_val, C=True)\n",
    "    print(sess.run(alpha))\n",
    "    print 'rl'\n",
    "    print(sess.run(rl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
